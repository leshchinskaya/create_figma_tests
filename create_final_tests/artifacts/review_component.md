### Чеклист 1: Форматирование и структура JSON (`TestCase`)

**Цель:** Проверить, что итоговый JSON-файл соответствует технической схеме и правилам синтаксиса. Эта проверка
касается "обертки" теста, а не его содержания. В ответе указывай только на найденные ошибки, но не исправляй их.
Используй пронумерованный список.

* **Формат `summary`:** Название теста строго соответствует формату `"Фича. Экран. Элемент - тест, уточнение"` и не
  содержит точки в конце?
* **Содержимое `description`:** Описание содержит обязательные ссылки на файл ТЗ и дизайн из Figma? Для тестов с API —
  указаны ли эндпоинт и ссылка на модель в Swagger?
* **Структура `testRepositoryPath`:** Путь соответствует иерархии `фича/экран`, написан в нижнем регистре и не содержит
  папок, основанных на типе теста (например, `/компоновка/`)?
* **Корректность типов:** Поля `priority`, `testCaseType` и `labels` заполнены в соответствии с правилами (например,
  `testCaseType` всегда `component`)?
* **Синтаксис JSON:** Отсутствуют ли синтаксические ошибки? Используются ли одинарные кавычки (`'`) для вложенных строк?
* **Форматирование `monospace`:** Отсутствуют ли обратные кавычки (`` ` ``) для форматирования? Используется ли вместо
  них конструкция `{{text}}`?
* **Форматирование эндпоинтов:** Параметры в эндпоинтах обернуты в угловые скобки (`<>`), например,
  `{{GET /users/<userId>}}`?

### Чеклист 2: Содержание и логика шагов теста (`steps`)

**Цель:** Проверить качество и логику самих тестовых шагов. Эта проверка сфокусирована на том, **как** написан тест.
В ответе указывай только на найденные ошибки, но не исправляй их.
Используй пронумерованный список.

* **Формулировки:** Соблюдена ли форма глаголов (инфинитив для `action`, декларатив для `result`)?
* **Атомарность шагов:** Объединены ли последовательные действия "триггер -> ожидание -> результат запроса" в один
  логический шаг, а не разбиты на несколько?
* **Отсутствие условности:** Отсутствует ли в `result` двусмысленная логика ("если/или")? Созданы ли отдельные тесты или
  шаги для каждой ветки поведения?
* **Обработка неоднозначности ТЗ:** Используется ли маркер `(?)` и префикс `TODO` в названии для тестов, основанных на
  предположениях из-за неполноты требований?
* **Защита от двойных тапов:** Проверена ли блокировка UI при повторном нажатии на элементы, инициирующие сетевой
  запрос?
* **Синхронизация состояний:** Проверен ли сценарий, когда действие над одним элементом (например, добавление в "
  Избранное") должно обновлять состояние этого же элемента в другом месте на экране?
* **Ограничение скоупа:** При переходе на экран из другой фичи, тест ограничивается проверкой самого факта перехода, не
  тестируя внутреннюю логику нового экрана?
* **Предусловия:** Предусловия, необходимые для шага, четко обозначены в поле `data` (или в `action`, если `data`
  занято)?

### Чеклист 3: Полнота и корректность тестового покрытия

**Цель:** Убедиться, что все требуемые типы тестов были созданы и ничего не упущено. Эта проверка отвечает на вопрос, *
*что** было протестировано. В ответе указывай только на найденные ошибки, но не исправляй их.
Используй пронумерованный список.

* **Компоновка:** Созданы ли тесты на компоновку для каждого экрана/шторки и для всех их состояний (Data, Error, Empty,
  Loading)?
* **Сетевые запросы:** Для каждого API-вызова созданы ли отдельные тесты на успешный ответ (включая Empty State) и на
  обработку всех видов ошибок?
* **Обработка ошибок:** В тестах на ошибки запросов покрыт ли полный набор системных ошибок (5xx, 4xx, таймаут, нет
  сети) и специфичные для эндпоинта ошибки (например, 401/403)? Покрыты ли ошибки целиком в соответствии со стратегией?
* **Кнопки "Повторить":** Для кнопок "Повторить" на экранах ошибок (Error State, заглушки пагинации) создан ли полный
  набор тестов на повторный запрос (успех и ошибка)?
* **Пагинация и PTR:** Если на экране есть пагинация или Pull-to-Refresh, покрыты ли они полным набором тестов (успех,
  ошибка, повтор)?
* **Логика UI:** Для каждого интерактивного элемента (поля ввода, кнопки, свитчи, карусели) созданы ли тесты,
  покрывающие всю его логику, включая позитивные и негативные проверки (например, валидация полей)?
* **Условная логика ТЗ:** Все ли условные состояния UI, явно описанные в ТЗ (например, `state=has_bonuses` vs
  `state=no_bonuses`), покрыты отдельными тестами?
* **Неявные требования:** Применены ли типовые проверки для UI-элементов (например, проверка заглушки для изображения
  при пустом `imageUrl`), даже если они не были явно описаны в ТЗ фичи?

### Чеклист 4: Типичные ошибки

В ответе указывай только на найденные ошибки, но не исправляй их. 
Используй пронумерованный список.

1. В описании проверок на запросы присутствуют ссылки на Swagger.
2. Формат названия соответствует правилам.
3. В проверках на запросы с ошибкой все виды ошибок расписаны явно и полно, в том числе в PTR, повторах на заглушках или
   пагинациях. 401 и 403 используется правильно (для refresh/логаут логики, а не для логики неавторизованного
   пользователя).
4. "Наверное" и неуверенность в ответе, при этом отсутствует (?) пометка и TODO в названии теста.
5. Условная логика или объединение шагов вместо явной разбивки на несколько шагов.
6. Покрыты не все элементы/экраны или их состояния.
7. В конце генерации не содержится сводка TODO.


### Агрегация 
<приложить все ответы ревью>

Объедини данный фидбек в один. Фокусируйся только на ошибках. Используй нумерованный список для удобства.