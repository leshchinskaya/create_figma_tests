# Верхнеуровневое овервью

Данный инструмент позволяет автоматизировать генерацию компонентных и сценарных тест-кейсов на основе набора артефактов:
технических требований (ТЗ), Swagger-спецификаций и макетов дизайна из Figma.

Процесс построен на двух основных рабочих потоках (workflows):

1. **Генерация компонентных тестов:** На этом этапе детально анализируются отдельные экраны, их состояния (Data, Error,
   Empty, Loading), UI-элементы и сетевые запросы. Результатом является набор компонентных тестов в Jira и CSV-файл,
   который служит входными данными для следующего этапа.
2. **Генерация сценарных тестов:** На основе ранее созданных компонентных тестов, а также ТЗ и Swagger, генерируются
   высокоуровневые end-to-end сценарии, проверяющие пользовательские пути (user flows) в рамках фичи.

Ключевым звеном в обоих потоках является использование AI (LLM), который получает на вход тщательно подготовленный
"промпт" со всеми артефактами и генерирует наборы тестов в формате JSON.

# Порядок работы

> Инструкция по последовательному выполнению шагов находится в `RUNBOOK.md`.
> Этот документ описывает назначение и использование каждого компонента.

### 1. Изначальная настройка

1. **Установка зависимостей:**
   Выполните `sh setup.sh`. Этот скрипт установит Python (если необходимо), создаст виртуальное окружение `venv` и
   установит все зависимости из `requirements.txt`.
2. **Создание файла конфигурации:**
   Скопируйте `config_template.py` в новый файл `config.py`.
3. **Заполнение конфигурации:**
   Откройте `config.py` и заполните все необходимые данные: токены Figma, учетные данные Jira, ключи проектов, ID
   кастомных полей и т.д. Включите `AUTOLAUNCH_FILES=True`, если хотите, чтобы сгенерированные файлы промптов и
   JSON-ответы открывались автоматически.

### 2. Подготовка артефактов для генерации

Перед генерацией тестов необходимо собрать все исходные данные.

1. **Генерация тестов по дизайну из Figma:**
    * **Скрипт:** `send_figma_tests_all_tests.py`
    * **Назначение:** Анализирует файл Figma, извлекает экраны и интерактивные элементы на основе фильтров в
      `config.py` (`FRAME_INCLUDE`, `ELEMENT_INCLUDE` и т.д.).
    * **Режим работы:** В `config.py` установите `OPERATIONAL_MODE = "FILE_EXPORT"`. В этом режиме скрипт не создает
      задачи в Jira, а формирует CSV-файл с перечнем UI-элементов.
    * **Результат:** В папке `create_final_tests/artifacts` будет создан файл `tests_from_figma.csv`, который
      используется как один из артефактов для генерации компонентных тестов.

2. **Сборка единого файла требований (ТЗ):**
    * **Скрипт:** `create_final_tests/folder_structure/gui_update_file_structure.py`
    * **Назначение:** Предоставляет графический интерфейс для выбора необходимых файлов и папок с технической
      документацией. Скрипт рекурсивно обходит выбранные директории и объединяет содержимое всех файлов в один.
    * **Конфигурация:** Пути для сканирования настраиваются в
      `create_final_tests/folder_structure/task_list_configuration.md`.
    * **Результат:** В папке `create_final_tests/artifacts` будет создан или обновлен файл `req.md`.

3. **Актуализация Swagger-спецификации:**
    * **Действие:** Поместите актуальный файл `swagger.yaml` в `create_final_tests/artifacts`. Если файл находится в
      другом месте, можно указать абсолютный или относительный путь к нему в `config.py` в переменной
      `SWAGGER_LOCAL_PATH`.

### 3. Генерация компонентных тестов

1. **Формирование промпта для AI:**
    * **Скрипт:** `generate_component_prompt.sh`
    * **Назначение:** Собирает все подготовленные артефакты (`req.md`, `swagger.yaml`, `tests_from_figma.csv`) и,
      используя шаблон `prompt_component.md`, генерирует единый текстовый файл-промпт.
    * **Результат:** В `create_final_tests/artifacts` создается файл `final_prompt_component.txt`.

2. **Работа с AI:**
    * **Действие:** Содержимое `final_prompt_component.txt` передается в AI.
    * **Ревью:** Ответ AI рекомендуется проверить с помощью чеклиста `create_final_tests/artifacts/review_component.md`,
      чтобы убедиться в качестве и полноте сгенерированных тестов.
    * **Результат:** Итоговый ответ от AI в формате JSON сохраняется в файл
      `create_final_tests/artifacts/component_tests.json`.

3. **Отправка тестов в Jira:**
    * **Скрипт:**
      `python3 -m create_final_tests.jira_sender --input create_final_tests/artifacts/component_tests.json --download-csv`
    * **Назначение:** Отправляет тест-кейсы из `component_tests.json` в Jira.
    * **Ключевая особенность:** Флаг `--download-csv` заставляет скрипт после создания задач в Jira выгрузить их обратно
      в виде CSV-файла.
    * **Результат:** Тесты созданы в Jira. В `create_final_tests/artifacts` появляется файл `component_tests.csv`,
      который является **обязательным артефактом** для генерации сценарных тестов.

### 4. Генерация сценарных тестов

1. **Формирование промпта для AI:**
    * **Скрипт:** `generate_scenario_prompt.sh`
    * **Назначение:** Аналогично компонентным тестам, собирает артефакты (`req.md`, `swagger.yaml` и *
      *`component_tests.csv`**) и по шаблону `prompt_scenario.md` генерирует промпт.
    * **Результат:** В `create_final_tests/artifacts` создается файл `final_prompt_scenario.txt`.

2. **Работа с AI:**
    * **Действие:** Содержимое `final_prompt_scenario.txt` передается в AI.
    * **Ревью:** Ответ проверяется с помощью чеклиста `create_final_tests/artifacts/review_scenario.md`.
    * **Результат:** Итоговый JSON сохраняется в файл `create_final_tests/artifacts/scenario_tests.json`.

3. **Отправка тестов в Jira:**
    * **Скрипт:** `python3 -m create_final_tests.jira_sender --input create_final_tests/artifacts/scenario_tests.json`
    * **Назначение:** Отправляет сценарные тест-кейсы из `scenario_tests.json` в Jira. Флаг `--download-csv` здесь
      обычно не используется.
    * **Результат:** Сценарные тесты созданы в Jira. В консоли будет выведена ссылка для просмотра созданных задач.